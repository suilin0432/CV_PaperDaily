|  创建人   |  知乎论文阅读专栏 | 个人博客 | 其他相关链接 |
|  ----  | ----  | ----  | ----  |
| ming71  | [论文笔记入口](https://zhuanlan.zhihu.com/c_1113860303082704896) | [chaser](https://ming71.github.io/) |   [CSDN](https://blog.csdn.net/mingqi1996) 

<span id="inline-blue">论文发布日期：2017.4 [CVPR]<p/span>

## 1. Insight

* 率先提出**不同的像素本身具有不同难度的可分性**，可以通过不同的分支设计，学习不同难分度的像素分割任务，从而提升分割精度；        
* 将低层确定的像素进行mask，不参与后面的计算，能够加速网络计算；        
* 相比MC模型的单个训练，这个可以端到端训练. 
<!-- more --> 

## 2. Deep Layer Cascade
<center><img src="http://chaserblog.test.upcdn.net/blogs/paper/Not-All-Pixes-Are-Equal/str1.png" alt="" style="width:90%" /></center>

&emsp;&emsp;通过三个分支实现不同难度的pix分割识别。设置统一的ρ=0.95，每个分支加上两个64x64x21的卷积层，其中21对应VOC的21类，再采用softmax在depth方向竞争确定pix的分类。以第一个分支为例，将得到的特征图经过卷积得到概率分布特征图后，筛选出大于ρ的概率类，直接确定该pix的label为对应的类别，并且后面用0mask阻断后面的传播。        
&emsp;&emsp;在这里被阻断的样本无非两类：        
&emsp;&emsp;（1）特别简单的分类任务，如牛肚子，背景，在这里直接确定，就不用参与后面的计算，加速模型       
&emsp;&emsp;（2）特别难分的对抗样本：如牛肚子中打分出现了几个车的像素，而且conf非常高。这类样本也在这里留下，可以直接计算损失即可，**如果后面层训练这种错误的难分样本，会导致网络过拟合，难以学习正确的特征**。        
&emsp;&emsp;对于分类概率小于0.95的属于本阶段不易分出的pix，传入下一个阶段进行同样的分割，后面依次如此，每个分支处理对应难度的pix分割任务。

## 3. Contribution
* 将简单和难分的pix使用不同的层进行区分学习，获得更好的效果
* 由于很多pix在浅层就直接确定了不参与后面的计算（通过mask 0-1），可以减少计算量。（实验证明设置ρ=0.95都能筛选掉30%以上的pix）
* 端到端的联合训练

## Conclusion
* 率先提出<u>不同的像素本身具有不同难度的可分性，根据这个区分难度进行按照不同难度的自适应（手工分级）学习分割任务</u>
* 浅层确定了像素的分类后，通过0-1mask不参与后面计算，相当于**Region-Conv**降低计算量，提速


<br>

<hr />